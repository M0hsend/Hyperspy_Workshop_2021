{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Working with lazy signals in HyperSpy\n",
    "\n",
    "Requires **HyperSpy 1.4.2 or above**\n",
    "\n",
    "This tutorial introduces to the processing of large dataset - which can not fit into memory - using HyperSpy. It introduce the concept of out-of-core computation algorithms (also refer as lazy processing) and the main difference between lazy and non-lazy processing as well as technicalities you need to be aware of to optimise performance.\n",
    "The corresponding section of the HyperSpy documentation is [the big data section](https://hyperspy.readthedocs.io/en/stable/user_guide/big_data.html#limitations).\n",
    "\n",
    "### Credits and changes\n",
    "\n",
    "* 12/04/2021 Magnus Nord. Change to using 4D-STEM dataset, instead of the EELS map.\n",
    "* 29/07/2019 Eric Prestat. Add more details and introduction for the M&M Sunday short course.\n",
    "* 15/03/2019 Francisco de la Pe√±a. Create tutorial for the HyperSpy workshop at ePSIC.\n",
    "\n",
    "## Table of contents\n",
    "1. [Introduction to lazy processing](#1.-Introduction-to-lazy-processing)\n",
    "2. [Loading data lazily](#2.-Loading-data-lazily)\n",
    "3. [Plotting lazily](#3.-Plotting-lazily)\n",
    "4. [Rebinning](#4.-Rebinning)\n",
    "5. [ROI in navigation dimension](#5.-ROI-in-navigation-dimension)\n",
    "6. [Summary](#6.-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to lazy processing\n",
    "\n",
    "Lazy processing refers to the use of [out-of-core computation algorithms](https://en.wikipedia.org/wiki/External_memory_algorithm) to process very large data, which are usually too large to fit into the computer's memory at one time. The main idea is to chunk the data in pieces, small enough, that can be processed in memory.\n",
    "\n",
    "HyperSpy internally uses the [dask library](https://docs.dask.org/en/latest/index.html), which implements the numpy interface to larger-than-memory or distributed environments. The typically workflow for processing data lazily which is on a disk:\n",
    "1. \"load\" data from disk with a defined chunking\n",
    "2. schedule operations\n",
    "3. do the computation\n",
    " \n",
    "Lets try this with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Load\" the data, by generating a big image with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = da.random.random(size=(50000, 50000), chunks=(1000, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedule operation, firsty taking the square root, then summing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = da.sqrt(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps 1 and 2 are very fast**, because nothing is actually done, other than initialising and scheduling the tasks to be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual calculation, using `compute`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 is slow**, because all the computation is performed at this stage. Most of the time, this is signficantly slower than in-memory processing, because the chunks of data needs to be read and written from/to disk on request of the scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of processing is very powerful when working with large datasets, but requires some knowledge to use properly.\n",
    "\n",
    "For more information about dask and its principle see http://matthewrocklin.com/slides/plotcon-2016.html. However, we're jumping onto the next step: how you can use this type of functionality in HyperSpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading data lazily\n",
    "\n",
    "The implementation of out-of-core computation in HyperSpy aims to make processing very large data (not fitting into memory) as seamlessly as possible and similar to in-memory data. This tutorial covers the main difference between lazy and non-lazy processing as well as technicalities you need to be aware of to optimise performance.\n",
    "\n",
    "As usual, we start by setting up the matplotlib backend and importing hyperspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import hyperspy.api as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we are going to start by loading 4D-STEM dataset, `lazy_dataset.hspy`. Note that its size is reduced quite a bit, to make it easier to download. The full dataset is `(256 x 256)` probe positions with `(256 x 256)` detector pixels, acquired at ePSIC a couple of years ago. The full dataset can be found at the Zenodo deposit, https://zenodo.org/record/3479124. The file itself: https://zenodo.org/record/3479124/files/fig1_021_sto_12bit_256x256_CL_2_5_1000us.emd?download=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hs.load(\"lazy_dataset.hspy\", lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what sort of object we have stored in the ``s`` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a scanning diffraction dataset with `(144 x 144)` probe positions, and `(144 x 144)` detector pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"nbytes\" attribute of the numpy array to calculate the size on disk\n",
    "print(s.data.nbytes / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is about 0.8 GB of data, which we actually could comfortably load into memory and process the standard way. However, we'll use this to show how this type of lazy processing can be done in HyperSpy.\n",
    "\n",
    "If you want to try this on a much bigger dataset after the workshop, you can check out this [Zenodo deposit](https://zenodo.org/record/4312960), specifically the [largest file](https://zenodo.org/record/4312960/files/fe60al40_stripe_pattern.hspy?download=1), which is a magnetic [STEM-DPC](https://en.wikipedia.org/wiki/Scanning_transmission_electron_microscopy#Differential_phase_contrast) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting lazily "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the data, we use `s.plot`, just as a non-lazy signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the navigation image, just the center part of the diffraction pattern is used. This to reduce the amount of time it takes to generate the navigation image.\n",
    "\n",
    "Note that there are some big improvements coming in the next version of HyperSpy with regards to plotting lazy signals.\n",
    "\n",
    "This navigator is stored in `s.navigator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.navigator.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we rather want a more annular dark-field (ADF) like contrast, we can utilize the region of interest functionality. Here, we use the `CircleROI` with an inner radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_roi = hs.roi.CircleROI(cx=72, cy=72, r=72, r_inner=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then make a new signal, `s_adf_sum` utilizing the `adf_roi`, the `nansum` function, and `.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_adf = adf_roi(s, axes=(2, 3))\n",
    "s_adf_sum = s_adf.nansum(axis=(2, 3), rechunk=False)\n",
    "s_adf_sum = s_adf_sum.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all of these operations are instantaneous, to actually do the calculations, use `.compute()`.\n",
    "\n",
    "Thanks to the lazy processing, we never have to load the full dataset into memory. So you can potentially do this to datasets which are much larger than your available memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_adf_sum.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set it as the navigator for `s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.navigator = s_adf_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important aspect of lazy processing is **chunking**. This is how the data is organized inside files, like `lazy_dataset.hspy`.\n",
    "\n",
    "For our 4-dimensional dataset here, the data is split into many smaller 4-dimensional chunks. To see this structure, we use `s.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important part is the `Chunk (16, 16, 16, 16)`, which means each chunk consist of `16 x 16` probe positions, and `16 x 16` detector pixels. Each time we want to access something inside a chunk, we need to load the whole chunk into memory.\n",
    "\n",
    "So for example, if we want to see what the value is for a single detector pixel at one specific probe position, we need to really get the full chunk. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_single = s.inav[0, 0].isig[0, 0]\n",
    "s_single.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires just as much reading from the harddrive as reading the full chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_single = s.inav[0:32, 0:32].isig[0:32, 0:32]\n",
    "s_single.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking is quite tricky, with there not being an \"ideal\" chunking strategy. There are always trade-offs. For now, we'll have a look to why this file is chunked this way.\n",
    "\n",
    "It makes it very easy to use `transpose` to flip the navigation dimensions, utilizing the same file. This means we can easily navigate the dataset as a function of detector pixels, instead of as a function of probe positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t = s.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also navigate a bit quicker using `navigator=\"slider\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.T.plot(navigator=\"slider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data reduction through rebinning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common way of exploring these large datasets, is through reducing their size so that they can fit inside the memory. One easy way of doing this is through `rebin`. By using `scale=(2, 2, 2, 2,)`, we reduce the number of probe positions by 4, and reduce the number of detector pixels by 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rebin = s.rebin(scale=(2, 2, 2, 2), rechunk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rebin.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_rebin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_rebin.data.nbytes / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now about 200 MB, which is due to reducing the number of data points 16 times, and increasing the bit depth to avoid losing information.\n",
    "\n",
    "Now we can finally compute it, to load the reduced dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rebin.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`s_rebin` is now a non-lazy signal, with its data loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_rebin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rebin.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or look at the transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rebin.T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processing the data using `s.map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the data, we can use the `s.map` function, which can apply arbitrary functions to each probe positions.\n",
    "\n",
    "Lets try to extract some more information from the diffraction patterns, by using edge detection. Here, we can utilize scikit-image's feature functions. For example: `skimage.feature.canny`.\n",
    "\n",
    "While we could pass the function directly to the `map` function, lets make our own custom function with some pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, import the canny function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make our function, which we will pass to `map`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_function(image):\n",
    "    image = canny(image.astype(\"float32\"), sigma=2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass the function to `s.map`. Where `inplace=False` means the function does not alter the original signal `s`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_canny = s.map(canny_edge_function, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a lazy signal, meaning the calculations haven't really been done yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `compute()`, we do the actually calculcations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_canny.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also save this lazy signal directly, without loading it into memory. This is useful when you're working with really big datasets.\n",
    "\n",
    "Having run `compute`, we now get a non-lazy signal, which we can plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_canny.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary\n",
    "\n",
    "Most operations can be performed *lazily* in HyperSpy:\n",
    "1. Visualisation\n",
    "2. Slicing and indexing\n",
    "3. Generic mathematical operations\n",
    "4. Machine learning\n",
    "5. Curve fitting\n",
    "\n",
    "See [the big data section](https://hyperspy.readthedocs.io/en/stable/user_guide/big_data.html#limitations) of the HyperSpy documentation for more information and to learn about the main difference between lazy and non-lazy signal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
